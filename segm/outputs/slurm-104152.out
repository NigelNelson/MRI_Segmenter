MOFED version '4.9-2.2.6' not available in this container.
No matching alternate version found.
Starting process with rank 0...
Process 0 is connected.
All processes are connected.
/home/nelsonni/.local/lib/python3.6/site-packages/torch/nn/functional.py:3635: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode)
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
pixdim[1,2,3] should be non-zero; setting 0 dims to 1
Resuming training from checkpoint: seg_tiny_mask_retrain/checkpoint.pth
Configuration:
algorithm_kwargs:
  batch_size: 8
  eval_freq: 2
  num_epochs: 64
  start_epoch: 64
amp: false
dataset_kwargs:
  batch_size: 8
  crop_size: 512
  dataset: ade20k
  image_size: 512
  normalization: vit
  num_workers: 10
  split: train
inference_kwargs:
  im_size: 512
  window_size: 512
  window_stride: 512
log_dir: seg_tiny_mask_retrain
net_kwargs:
  backbone: vit_tiny_patch16_384
  d_model: 192
  decoder:
    drop_path_rate: 0.0
    dropout: 0.1
    n_cls: 8
    n_layers: 2
    name: mask_transformer
  distilled: false
  drop_path_rate: 0.1
  dropout: 0.0
  image_size: !!python/tuple
  - 512
  - 512
  n_cls: 8
  n_heads: 3
  n_layers: 12
  normalization: vit
  patch_size: 16
optimizer_kwargs:
  clip_grad: null
  epochs: 64
  iter_max: 2432
  iter_warmup: 0.0
  lr: 0.001
  min_lr: 1.0e-05
  momentum: 0.9
  opt: sgd
  poly_power: 0.9
  poly_step_size: 1
  sched: polynomial
  weight_decay: 0.0
resume: true
version: normal
world_batch_size: 8

Success: /data/ur/bukowy/LaViolette_Data/Prostates/1125/11
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1125/10
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1148/5
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1148/6
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1125/8
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1126/6
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1125/7
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1126/10
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1126/8
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1125/9
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1126/11
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1148/7
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1126/7
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1148/9
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1126/9
Success: /data/ur/bukowy/LaViolette_Data/Prostates/1148/8
Train dataset length: 304
Val dataset length: 16
Encoder parameters: 5876392
Decoder parameters: 1002448
